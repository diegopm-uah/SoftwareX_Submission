{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot   as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.manual_seed(101)\n",
    "torch.cuda.manual_seed(101)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img1_dir, img2_dir, img3_dir, coords_file, transform=None):\n",
    "        # Directorios de imágenes y archivo CSV de coordenadas\n",
    "        self.img1_dir = img1_dir\n",
    "        self.img2_dir = img2_dir\n",
    "        self.img3_dir = img3_dir\n",
    "        self.coords = np.load(coords_file)[:, 1:]\n",
    "        # self.coords = self.coords.reshape(self.coords.shape[0],int(self.coords.shape[1]/3),3)\n",
    "        # for i in range(self.coords.shape[0]):\n",
    "        #     # Ordenar por las columnas 2 (z), 1 (y) y 0 (x)\n",
    "        #     self.coords[i] = self.coords[i][np.lexsort((self.coords[i][:, 2], self.coords[i][:, 1], self.coords[i][:, 0]))]\n",
    "        # self.coords = self.coords.reshape(self.coords.shape[0],self.coords.shape[1]*self.coords.shape[2])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Cargar las tres imágenes\n",
    "        img1_path = os.path.join(self.img1_dir, f\"isar_{idx+1}_1.png\")\n",
    "        img2_path = os.path.join(self.img2_dir, f\"isar_{idx+1}_2.png\")\n",
    "        img3_path = os.path.join(self.img3_dir, f\"isar_{idx+1}_3.png\")\n",
    "        img1 = Image.open(img1_path).convert(\"L\")\n",
    "        img2 = Image.open(img2_path).convert(\"L\")\n",
    "        img3 = Image.open(img3_path).convert(\"L\")\n",
    "\n",
    "        # Aplicar transformaciones si las hay\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "\n",
    "        # Obtener el vector de coordenadas de salida\n",
    "        coords = torch.tensor(self.coords[idx,:], dtype=torch.float32)\n",
    "\n",
    "        return img1.to(device), img2.to(device), img3.to(device), coords.to(device)\n",
    "\n",
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModule, self).__init__()\n",
    "        # Capas convolucionales\n",
    "        self.conv1 = nn.LazyConv2d(96, kernel_size=22, stride=2, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.LazyConv2d(256, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.LazyConv2d(384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.LazyConv2d(384, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.LazyConv2d(256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.Flatten(x)\n",
    "        return x\n",
    "    \n",
    "class CoordinatePredictor(nn.Module):\n",
    "    def __init__(self,coords_width):\n",
    "        super(CoordinatePredictor, self).__init__()\n",
    "        # CNN compartida para las tres imágenes\n",
    "        self.cnn = CNNModule()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.LazyLinear(4096)  # Ajustar el tamaño si las imágenes son diferentes\n",
    "        self.fc2 = nn.LazyLinear(4096)\n",
    "        #self.Dropout = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.LazyLinear(coords_width)  # 3*N salidas, una por coordenada (x, y, z) de cada uno de los N vertices\n",
    "\n",
    "    def forward(self, image1, image2, image3):\n",
    "        # Procesar cada imagen a través de la CNN\n",
    "        image1_features = self.cnn(image1)\n",
    "        image2_features = self.cnn(image2)\n",
    "        image3_features = self.cnn(image3)\n",
    "\n",
    "        # Concatenar las características de las tres imágenes\n",
    "        concat_images = torch.cat((image1_features, image2_features, image3_features), dim=1)\n",
    "\n",
    "        # Pasar por las capas densas\n",
    "        x = F.relu(self.fc1(concat_images))\n",
    "        #x = self.Dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = self.Dropout(x)\n",
    "        output_coords = self.fc3(x)\n",
    "\n",
    "        return output_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 55, 55]          46,560\n",
      "              ReLU-2           [-1, 96, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
      "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
      "              ReLU-5          [-1, 256, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-10          [-1, 384, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "          Flatten-14                 [-1, 9216]               0\n",
      "        CNNModule-15                 [-1, 9216]               0\n",
      "           Conv2d-16           [-1, 96, 55, 55]          46,560\n",
      "             ReLU-17           [-1, 96, 55, 55]               0\n",
      "        MaxPool2d-18           [-1, 96, 27, 27]               0\n",
      "           Conv2d-19          [-1, 256, 27, 27]         614,656\n",
      "             ReLU-20          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-21          [-1, 256, 13, 13]               0\n",
      "           Conv2d-22          [-1, 384, 13, 13]         885,120\n",
      "             ReLU-23          [-1, 384, 13, 13]               0\n",
      "           Conv2d-24          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-25          [-1, 384, 13, 13]               0\n",
      "           Conv2d-26          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-27          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-28            [-1, 256, 6, 6]               0\n",
      "          Flatten-29                 [-1, 9216]               0\n",
      "        CNNModule-30                 [-1, 9216]               0\n",
      "           Conv2d-31           [-1, 96, 55, 55]          46,560\n",
      "             ReLU-32           [-1, 96, 55, 55]               0\n",
      "        MaxPool2d-33           [-1, 96, 27, 27]               0\n",
      "           Conv2d-34          [-1, 256, 27, 27]         614,656\n",
      "             ReLU-35          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-36          [-1, 256, 13, 13]               0\n",
      "           Conv2d-37          [-1, 384, 13, 13]         885,120\n",
      "             ReLU-38          [-1, 384, 13, 13]               0\n",
      "           Conv2d-39          [-1, 384, 13, 13]       1,327,488\n",
      "             ReLU-40          [-1, 384, 13, 13]               0\n",
      "           Conv2d-41          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-42          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-43            [-1, 256, 6, 6]               0\n",
      "          Flatten-44                 [-1, 9216]               0\n",
      "        CNNModule-45                 [-1, 9216]               0\n",
      "           Linear-46                 [-1, 4096]     113,250,304\n",
      "           Linear-47                 [-1, 4096]      16,781,312\n",
      "           Linear-48                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 141,406,392\n",
      "Trainable params: 141,406,392\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 16777216.00\n",
      "Forward/backward pass size (MB): 33.05\n",
      "Params size (MB): 539.42\n",
      "Estimated Total Size (MB): 16777788.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Definir las transformaciones (por ejemplo, redimensionar las imágenes y normalizarlas)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),                                        # Cambia esto según el tamaño de tus imágenes\n",
    "    transforms.ToTensor(),                                              # Convertir las imágenes a tensores\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])     # Normalización\n",
    "])\n",
    "\n",
    "# Crear el dataset personalizado\n",
    "dataset = CustomDataset(\n",
    "    img1_dir=\"C:\\\\Users\\\\Diego\\\\Desktop\\\\N101\\\\Datasets\\\\Regression\\\\Cube\\\\Img\\\\ISAR\", \n",
    "    img2_dir=\"C:\\\\Users\\\\Diego\\\\Desktop\\\\N101\\\\Datasets\\\\Regression\\\\Cube\\\\Img\\\\ISAR\", \n",
    "    img3_dir=\"C:\\\\Users\\\\Diego\\\\Desktop\\\\N101\\\\Datasets\\\\Regression\\\\Cube\\\\Img\\\\ISAR\",\n",
    "    coords_file=\"C:\\\\Users\\\\Diego\\\\Desktop\\\\N101\\\\Datasets\\\\Regression\\\\Cube\\\\Img\\\\coords.npy\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación\n",
    "train_size = int(0.7 * len(dataset))  # 70% para entrenamiento\n",
    "val_size = int(0.15 * len(dataset))  # 15% para validación\n",
    "test_size = len(dataset) - train_size - val_size  # 15% para test\n",
    "\n",
    "generator = torch.Generator().manual_seed(101)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "# Crear DataLoaders para iterar sobre los datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "# Inicializar modelo\n",
    "model = CoordinatePredictor(dataset.coords.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\AppData\\Local\\Temp\\ipykernel_12180\\2680781036.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('C:\\\\Users\\\\Diego\\\\Desktop\\\\N101\\\\CNN\\\\Modelos\\\\Cube_ISAR_1000samples_100ep_32bs_noroot.pth',map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CoordinatePredictor(\n",
       "  (cnn): CNNModule(\n",
       "    (conv1): Conv2d(1, 96, kernel_size=(22, 22), stride=(2, 2), padding=(1, 1))\n",
       "    (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (ReLU): ReLU()\n",
       "    (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc1): Linear(in_features=27648, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (fc3): Linear(in_features=4096, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar un modelo\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\Diego\\\\Desktop\\\\N101\\\\CNN\\\\Modelos\\\\Cube_ISAR_1000samples_100ep_32bs_noroot.pth',map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92d7f50aa3440b8b3333c7c89908260",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "# Importante incluir esta linea al comienzo de la celda donde se quiere visualizar el resultado\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "random_ch = np.random.randint(0, len(test_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (img1, img2, img3, target_coords) in enumerate(test_loader):\n",
    "        if i == random_ch:\n",
    "            sample_im1 = img1[0,0,:].reshape(1,1,img1.shape[2],img1.shape[3]).to(device)\n",
    "            sample_im2 = img2[0,0,:].reshape(1,1,img2.shape[2],img2.shape[3]).to(device)\n",
    "            sample_im3 = img3[0,0,:].reshape(1,1,img3.shape[2],img3.shape[3]).to(device)\n",
    "            sample_target = target_coords[0,:].reshape(1,-1)\n",
    "            break\n",
    "\n",
    "def plot_sample(output, target):\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "    ax.axes.set_xlim3d(left=-2, right=2) \n",
    "    ax.axes.set_ylim3d(bottom=-2, top=2)\n",
    "    ax.axes.set_zlim3d(bottom=-2, top=2) \n",
    "    fig.add_axes(ax)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    ax.scatter(output[:,0], output[:,1], output[:,2], c='red')\n",
    "    ax.scatter(target[:,0], target[:,1], target[:,2], c='blue')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "output = model(sample_im1, sample_im2, sample_im3)[0].reshape((-1,3)).detach().cpu().numpy()\n",
    "target = sample_target.reshape((-1,3)).detach().cpu().numpy()\n",
    "plot_sample(output,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2175557628041400\n"
     ]
    }
   ],
   "source": [
    "print(random_ch)\n",
    "print(torch.seed())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
